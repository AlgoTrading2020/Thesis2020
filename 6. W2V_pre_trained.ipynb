{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_clf__multi_class</th>\n",
       "      <th>param_clf__random_state</th>\n",
       "      <th>param_clf__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.900113</td>\n",
       "      <td>0.037090</td>\n",
       "      <td>0.026585</td>\n",
       "      <td>0.011968</td>\n",
       "      <td>0.001</td>\n",
       "      <td>auto</td>\n",
       "      <td>42</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 0.001, 'clf__multi_class': 'auto', ...</td>\n",
       "      <td>0.380442</td>\n",
       "      <td>0.379045</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.374243</td>\n",
       "      <td>0.378901</td>\n",
       "      <td>0.377096</td>\n",
       "      <td>0.002982</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.411529</td>\n",
       "      <td>0.222132</td>\n",
       "      <td>0.019395</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.001</td>\n",
       "      <td>auto</td>\n",
       "      <td>42</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'clf__C': 0.001, 'clf__multi_class': 'auto', ...</td>\n",
       "      <td>0.389057</td>\n",
       "      <td>0.383469</td>\n",
       "      <td>0.385887</td>\n",
       "      <td>0.374010</td>\n",
       "      <td>0.384956</td>\n",
       "      <td>0.383476</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.599058</td>\n",
       "      <td>0.114169</td>\n",
       "      <td>0.014591</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>42</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 1, 'clf__multi_class': 'auto', 'clf...</td>\n",
       "      <td>0.406985</td>\n",
       "      <td>0.396508</td>\n",
       "      <td>0.412436</td>\n",
       "      <td>0.384257</td>\n",
       "      <td>0.411039</td>\n",
       "      <td>0.402245</td>\n",
       "      <td>0.010584</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.760546</td>\n",
       "      <td>0.118181</td>\n",
       "      <td>0.019998</td>\n",
       "      <td>0.008579</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>42</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'clf__C': 1, 'clf__multi_class': 'auto', 'clf...</td>\n",
       "      <td>0.407451</td>\n",
       "      <td>0.394412</td>\n",
       "      <td>0.410806</td>\n",
       "      <td>0.389148</td>\n",
       "      <td>0.412203</td>\n",
       "      <td>0.402804</td>\n",
       "      <td>0.009283</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.191623</td>\n",
       "      <td>0.324937</td>\n",
       "      <td>0.020801</td>\n",
       "      <td>0.006716</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>42</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 4, 'clf__multi_class': 'auto', 'clf...</td>\n",
       "      <td>0.407916</td>\n",
       "      <td>0.400233</td>\n",
       "      <td>0.411737</td>\n",
       "      <td>0.387750</td>\n",
       "      <td>0.414765</td>\n",
       "      <td>0.404480</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.519018</td>\n",
       "      <td>0.460690</td>\n",
       "      <td>0.013302</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>42</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'clf__C': 4, 'clf__multi_class': 'auto', 'clf...</td>\n",
       "      <td>0.408149</td>\n",
       "      <td>0.403492</td>\n",
       "      <td>0.411039</td>\n",
       "      <td>0.386586</td>\n",
       "      <td>0.412203</td>\n",
       "      <td>0.404294</td>\n",
       "      <td>0.009350</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_clf__C  \\\n",
       "0       0.900113      0.037090         0.026585        0.011968        0.001   \n",
       "1       5.411529      0.222132         0.019395        0.007181        0.001   \n",
       "2       2.599058      0.114169         0.014591        0.002577            1   \n",
       "3       4.760546      0.118181         0.019998        0.008579            1   \n",
       "4       4.191623      0.324937         0.020801        0.006716            4   \n",
       "5       4.519018      0.460690         0.013302        0.002862            4   \n",
       "\n",
       "  param_clf__multi_class param_clf__random_state param_clf__solver  \\\n",
       "0                   auto                      42         liblinear   \n",
       "1                   auto                      42              saga   \n",
       "2                   auto                      42         liblinear   \n",
       "3                   auto                      42              saga   \n",
       "4                   auto                      42         liblinear   \n",
       "5                   auto                      42              saga   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'clf__C': 0.001, 'clf__multi_class': 'auto', ...           0.380442   \n",
       "1  {'clf__C': 0.001, 'clf__multi_class': 'auto', ...           0.389057   \n",
       "2  {'clf__C': 1, 'clf__multi_class': 'auto', 'clf...           0.406985   \n",
       "3  {'clf__C': 1, 'clf__multi_class': 'auto', 'clf...           0.407451   \n",
       "4  {'clf__C': 4, 'clf__multi_class': 'auto', 'clf...           0.407916   \n",
       "5  {'clf__C': 4, 'clf__multi_class': 'auto', 'clf...           0.408149   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.379045           0.372846           0.374243           0.378901   \n",
       "1           0.383469           0.385887           0.374010           0.384956   \n",
       "2           0.396508           0.412436           0.384257           0.411039   \n",
       "3           0.394412           0.410806           0.389148           0.412203   \n",
       "4           0.400233           0.411737           0.387750           0.414765   \n",
       "5           0.403492           0.411039           0.386586           0.412203   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.377096        0.002982                6  \n",
       "1         0.383476        0.005074                5  \n",
       "2         0.402245        0.010584                4  \n",
       "3         0.402804        0.009283                3  \n",
       "4         0.404480        0.009676                1  \n",
       "5         0.404294        0.009350                2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import gensim\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "def read_data():\n",
    "    df = pd.read_json('./0.5percent_threshold_20100101-20191231.json')\n",
    "    return df\n",
    "\n",
    "def lowercase(text):\n",
    "    #lowercase all words\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def swe():\n",
    "    #pre-trained model imported from this site: http://vectors.nlpl.eu/\n",
    "    import zipfile\n",
    "    repository = \"C:/Users/Fredrik/Documents\"\n",
    "    with zipfile.ZipFile(repository + \"/69.zip\", \"r\") as archive:\n",
    "        stream = archive.open(\"model.txt\")\n",
    "    wv = gensim.models.KeyedVectors.load_word2vec_format(stream, binary=False, unicode_errors='replace')\n",
    "    \n",
    "    #replace the raw vectors with the cosine similarity vectors\n",
    "    wv.init_sims(replace=True)\n",
    "    return wv\n",
    "\n",
    "def word_averaging(wv, words):\n",
    "    #wv is the model, words is the words in a document\n",
    "    \n",
    "    #Create a list\n",
    "    mean = []\n",
    "    #Iterate over the words\n",
    "    for word in words:\n",
    "        \n",
    "        #Checks if the word is of type np.ndarray (i.e. if each word is already represented by its vectors).\n",
    "        #If True, append the already extracted vectors to the list \"mean\".\n",
    "        #Elif False, first extract and then append the word vectors to the list \"mean\" for a word \n",
    "        #if it is in the word embeddings vocabulary. \n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.vectors_norm[wv.vocab[word].index])\n",
    "    \n",
    "    #if a document contains words that are not included in the word embeddings vocabulary, it won't receive any vectors.\n",
    "    #In place, return the same number of zeros as there are word dimensions. There are two such rows, \n",
    "    #one in train and one in test. Since they are so few, and since they have not been removed for other models, \n",
    "    #we do not remove them during the model evaluation step. \n",
    "    if not mean:\n",
    "        return np.zeros(wv.vector_size,)\n",
    "    \n",
    "    #Each document has varying number of words, meaning in each \"mean\" list there are \n",
    "    #(no. of words) * (no. of dimensions for each word), e.g. 1683 * 100 in one document and 843 * 100 in another.\n",
    "    #The below code snippet averages each dimension, e.g. creates 100 np.float32 numbers per document.\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def word_averaging_list(wv, corpus):\n",
    "    \n",
    "    #[word_averaging(wv, document) for document in corpus] returns a list (corpus) of arrays (documents), \n",
    "    #Each document (\"mean\") is one array\n",
    "    #np.vstack concatenates these arrays, instead returning an array (corpus) of lists (documents).\n",
    "    return np.vstack([word_averaging(wv, document) for document in corpus])\n",
    "\n",
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    \n",
    "    #Using the nltk package for a more advanced tokenizing of (1) sentences and (2) words\n",
    "    #as they are usually written in Swedish, to possibly improve quality compared to using mere spaces.\n",
    "    for sent in nltk.sent_tokenize(text, language='swedish'):\n",
    "        for word in nltk.word_tokenize(sent, language='swedish'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens\n",
    "\n",
    "def transform(text, wv):\n",
    "#Create a numpy array (corpus) of lists (documents) of tokens (words)\n",
    "#Subsequently average each dimension (100) of all words in each document\n",
    "    tokenized = text.apply(lambda document: w2v_tokenize_text(document)).values\n",
    "    word_average = word_averaging_list(wv, tokenized)\n",
    "    return word_average\n",
    "    \n",
    "#import dataset\n",
    "df = read_data()\n",
    "\n",
    "X = df.text\n",
    "y = df.alpha_label\n",
    "X = X.apply(lowercase)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2, stratify=y)\n",
    "\n",
    "#import pre-trained model and vocabulary\n",
    "wv = swe()\n",
    "\n",
    "X_train_transformed = transform(X_train, wv)\n",
    "\n",
    "params={'clf__solver': ['liblinear', 'saga'],\n",
    "        'clf__multi_class':['auto'],\n",
    "        'clf__C':[0.001, 1, 4],\n",
    "        'clf__random_state':[42]}\n",
    "\n",
    "pipe = Pipeline([('clf', LogisticRegression())\n",
    "                ])\n",
    "\n",
    "grid = GridSearchCV(pipe, params, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train_transformed, y_train)\n",
    "\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
